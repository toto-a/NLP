# NLP from scratch + Fine tuning with Hugging Face


## Overview
This repository provides a codebase for Natural Language Processing (NLP) tasks, starting from building models from scratch and to fine-tuning using the with the Hugging Face library.

## Models 
A simple causal model for a biagram langage model can be found [Biagram_Model](https://github.com/toto-a/NLP-from-scratch-/tree/main/Example_Transformer_Biagram) alongside some of notes of the makemore series by Andrej Karpathy 

A simple RNN/ LSTM cell model can be found here [rnn](https://github.com/toto-a/NLP-from-scratch-/tree/main/RNN%20%7C%20LSTM)

A simple transformer for translation w\ hugging face [Transformers](https://github.com/toto-a/NLP-from-scratch-/tree/main/Build_Transformers)

Inference code for llama2 [Llama2](https://github.com/toto-a/NLP-from-scratch-/tree/main/Build_llama2)

A simple GPT model [GPT](https://github.com/toto-a/NLP-from-scratch-/tree/main/Build_gpt) 

## Note 
Disclaimer : The models and implementations in this repository are based on my understanding of NLP concepts and techniques. While I strive for accuracy and reliability, the content provided here may not reflect the latest advancements or best practices in the field.

Things to finish : 
[ ] Training script for gpt 
